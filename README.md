Dart bindings to the whisper.cpp library.

## Features

These bindings were generated by ffigen, but higher level wrappers have been manually written.
In general, there's a wrapper for a Whisper Model to be loaded by file, with the latest FFI advancements, like [NativeFinalizers](https://api.dart.dev/stable/3.1.1/dart-ffi/NativeFinalizer-class.html) and [NativeCallables](https://api.dart.dev/stable/3.1.1/dart-ffi/NativeCallable-class.html).
## Getting started

To use this package, you must supply a precompiled dynamic library for whisper.cpp. Do keep in mind that this package most of the time targets the master branch of the [whisper.cpp](https://github.com/ggerganov/whisper.cpp) repo, since whisper.cpp is not stablilized enough to target releases.

## Usage

Load an wav file in the right format and pass it to the model.

```dart
import 'dart:ffi';

void main(List<String> arguments) {
    // Replace this with your library path or name.
    final dll = DynamicLibrary.open('whisper.dll'); 
    final ffi = WhisperBindings(dll);
    // This model supports setting the language to predict
    final model = WhisperModel.fromPath(ffi, 'path/to/ggml-base.bin', language: 'auto'); 
    if(arguments > 1){
        final audioPath = arguments[1];
        // Parse the wav file and get samples data in a buffer.
        final sampleRate = WHISPER_SAMPLE_RATE;
        // Whisper parses audio in 30s chunks.
        const whisperSecondsProcessed = 30;
        final sampleCount = sampleRate * whisperSecondsProcessed;
        final samplesPtr = calloc.alloc(sampleCount * sizeOf<Float>).cast<Float>();
        // Fill out the audio samples somehow.


        // This call has optional arguments for progress callbacks.
        model.whisperFull(samplesPtr, sampleCount);
        print("Detected speech: ${model.getAllSegments()}");
    }
}
```

## Additional information

PRs are welcome! 
